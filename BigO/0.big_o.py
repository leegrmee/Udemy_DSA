# Big O measures worst case

# Big O is a way of comparing code 1 and code 2 mathematically about how efficient they run.

# Time complexity is a way of describing how fast a function runs.
# it is measuerd in the number of operations it takes to complete
# Space complexity is a way of describing how much memory a function uses.

"""
When discussing time complexity, we utilize three primary concepts: Omega (Ω), Theta (Θ), and Big O (O).
Omega (Ω) represents the best-case scenario, indicating the lower bound of an algorithm's running time.
Theta (Θ) describes the average-case scenario, providing a tight bound where the running time grows proportionally with the input size.
Big O (O) characterizes the worst-case scenario, outlining the upper bound of an algorithm's running time.
Among these, Big O is the most commonly used measure for time complexity. 
This is because understanding the worst-case time complexity allows us to 
guarantee that an algorithm will not exceed a certain time limit, 
ensuring reliability and efficiency even in the most demanding situations. 
By focusing on Big O, 
developers can make informed decisions about the scalability and performance of their functions, 
ensuring that they perform optimally as input sizes grow.
"""


"""
O of n squared : Loop witin a loop
O on n: Propotional
O of log n :Divide and Conquer/분할 정복
O of 1: Constant


"""


"""
1)
O of n
"""


def print_items(n):
    for i in range(n):
        print(i)


print_items(10)

"""
One of the rules of simplifying Big O is to drop constants.
O(2n) -> O(n)
It doesn't matter if it's O of two n , ten n or 100 n, we can drop the constants.
Example:

def print_items(n):
    for i in range(n):
        print(i)
    
    for j in range(n):
        print(j)

print_items(10)
"""

"""
2)
O of n^2  (O of n squared)
using nested loops
"""


def print_items(n):
    """
    This function takes one integer argument, n, and prints out a pair of numbers (i, j)
    for every possible combination of i and j in the range of 0 up to but not including n.
    Each pair (i, j) is printed on a new line. i and j iterate over the range independently,
    so every combination of i and j in the range should be printed.
    The output of the function should be a series of pairs, printed one after the other, each on a new line.
    The pairs should be printed in the order that they are generated by the nested loops.
    """
    for i in range(n):
        for j in range(n):
            print(i, j)


print_items(10)

"""
One of simplifications of Big O is to drop Non dominant terms.
O(n^2 + n) -> O(n^2)
As a percentage of the total number of operations, the n time is insignificant.


def print_items(n):
    for i in range(n):
        for j in range(n):
            print(i, j)
    #O of n^2 times
    
    for k in range(n):
        print(k)
    #O of n times

print_items(10)
"""


"""
3)
0(1)
O of 1
- called constant time
- as n increasees, the number of operations is constant
- it doesn't matter if it's O of 1, 100 or 1000, it's still O of 1
"""


def add_items(n):
    return n + n


print(add_items(10))


"""
4)
0(log n)
O of log n
- it is far more efficient than O of n or O of n^2
"""
